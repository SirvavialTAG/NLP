{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "NLP_lab3.ipynb",
      "authorship_tag": "ABX9TyP90YvuRZ1ZTAlW10LCj2Xd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SirvavialTAG/NLP/blob/main/NLP_lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x-uYyR3RuD46"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция активация (сигмоида)\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "dNQ3QeL7_LE9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Производная сигмоиды\n",
        "def sigmoid_deriative(f_x):\n",
        "  return f_x * (1 - f_x)"
      ],
      "metadata": {
        "id": "bOG5wtjXAEBf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "  def __init__(self, input=2, hidden=3, output=1):\n",
        "    self.input_neurons = input\n",
        "    self.hidden_neurons = hidden\n",
        "    self.output_neurons = output\n",
        "\n",
        "    # Веса между входным и скрытым слоем + смещения для скрытого слоя\n",
        "    self.weights_input_hidden = np.random.uniform(-1, 1, (self.input_neurons, self.hidden_neurons))\n",
        "    self.bias_hidden = np.zeros((1, self.hidden_neurons))\n",
        "\n",
        "    # Веса между скрытым и выходным слоем + смещения для выходного слоя\n",
        "    self.weights_hidden_output = np.random.uniform(-1, 1, (self.hidden_neurons, self.output_neurons))\n",
        "    self.bias_output = np.zeros((1, self.output_neurons))\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    \"\"\"Прямое распространение (От входов к выходу)\"\"\"\n",
        "    self.hidden_in = np.dot(inputs, self.weights_input_hidden) + self.bias_hidden\n",
        "    self.hidden_out = sigmoid(self.hidden_in)\n",
        "\n",
        "    self.output_in = np.dot(self.hidden_out, self.weights_hidden_output) + self.bias_output\n",
        "    self.result = sigmoid(self.output_in)\n",
        "\n",
        "    return self.result\n",
        "\n",
        "  def backward(self, inputs, target, learning_rate=0.1):\n",
        "    \"\"\"Обратное распространение ошибки\"\"\"\n",
        "    # Вычисление дельты выходного слоя\n",
        "    output_error = target - self.result\n",
        "    output_delta = output_error * sigmoid_deriative(self.result)\n",
        "\n",
        "    # Вычисление дельты скрытого слоя\n",
        "    hidden_error = output_delta.dot(self.weights_hidden_output.T)\n",
        "    hidden_delta = hidden_error * sigmoid_deriative(self.hidden_out)\n",
        "\n",
        "    # Обновление весов\n",
        "    self.weights_hidden_output += self.hidden_out.T.dot(output_delta) * learning_rate\n",
        "    self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
        "    self.weights_input_hidden += inputs.T.dot(hidden_delta) * learning_rate\n",
        "    self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "  def train(self, dataset, epochs=10000):\n",
        "    input_data = np.array([item[0] for item in dataset])\n",
        "    target = np.array([item[1] for item in dataset]).reshape(-1, 1)\n",
        "    for epoch in range(epochs):\n",
        "      self.forward(input_data)\n",
        "      self.backward(input_data, target)\n",
        "\n",
        "      if epoch % 500 == 0:\n",
        "        loss = np.mean(np.abs(target - self.result))\n",
        "        print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
        "\n",
        "  def predict(self, inputs):\n",
        "        return (self.forward(inputs) > 0.5).astype(int)\n",
        "\n",
        "  def evaluate(self, dataset):\n",
        "    for inputs, target in dataset:\n",
        "      prediction = self.predict(np.array([inputs]))[0][0]\n",
        "      print(f\"Вход: {inputs}, Цель: {target}, Предсказание: {prediction}\")"
      ],
      "metadata": {
        "id": "TNBcsEJLi7hK"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TestNeuralNetwork = NeuralNetwork(2, 5, 1)\n",
        "\n",
        "train_dataset = [\n",
        "    ([1, 1], 1),\n",
        "    ([-1, -1], 1),\n",
        "    ([2, 2], 0),\n",
        "    ([0, 3], 0),\n",
        "    ([1.3, 3], 0),\n",
        "    ([1.2, 1.5], 1),\n",
        "    ([1.7, 1.6], 0),\n",
        "]\n",
        "\n",
        "test_dataset = [\n",
        "    ([0, 1], 1),\n",
        "    ([-1, 0], 1),\n",
        "    ([3, 2], 0),\n",
        "    ([1, 2], 0),\n",
        "    ([1.4, 1.4], 1),\n",
        "    ([1.5, 1.5], 0),\n",
        "    ([1.41419, 1.41419], 1),\n",
        "]\n",
        "\n",
        "print('\\n--Обучение--')\n",
        "TestNeuralNetwork.train(train_dataset, epochs=8001)\n",
        "\n",
        "print('\\n--Тесты--')\n",
        "TestNeuralNetwork.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7ziUM5KuLkU",
        "outputId": "900dcdf3-116f-4591-fc32-adf401c928b9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--Обучение--\n",
            "Epoch 0: Loss = 0.4739\n",
            "Epoch 500: Loss = 0.2393\n",
            "Epoch 1000: Loss = 0.1633\n",
            "Epoch 1500: Loss = 0.1229\n",
            "Epoch 2000: Loss = 0.0973\n",
            "Epoch 2500: Loss = 0.0799\n",
            "Epoch 3000: Loss = 0.0675\n",
            "Epoch 3500: Loss = 0.0583\n",
            "Epoch 4000: Loss = 0.0514\n",
            "Epoch 4500: Loss = 0.0460\n",
            "Epoch 5000: Loss = 0.0417\n",
            "Epoch 5500: Loss = 0.0382\n",
            "Epoch 6000: Loss = 0.0353\n",
            "Epoch 6500: Loss = 0.0329\n",
            "Epoch 7000: Loss = 0.0308\n",
            "Epoch 7500: Loss = 0.0290\n",
            "Epoch 8000: Loss = 0.0275\n",
            "\n",
            "--Тесты--\n",
            "Вход: [0, 1], Цель: 1, Предсказание: 1\n",
            "Вход: [-1, 0], Цель: 1, Предсказание: 1\n",
            "Вход: [3, 2], Цель: 0, Предсказание: 0\n",
            "Вход: [1, 2], Цель: 0, Предсказание: 0\n",
            "Вход: [1.4, 1.4], Цель: 1, Предсказание: 1\n",
            "Вход: [1.5, 1.5], Цель: 0, Предсказание: 0\n",
            "Вход: [1.41419, 1.41419], Цель: 1, Предсказание: 1\n"
          ]
        }
      ]
    }
  ]
}