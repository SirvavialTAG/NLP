{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGJn8Lh4nK5tvp+1xMrdma",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SirvavialTAG/NLP/blob/main/NLP_lab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF4cPd_IhB0A",
        "outputId": "77bed2d6-2633-45bb-af05-6d884a46acbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymorphy3 in /usr/local/lib/python3.11/dist-packages (2.0.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: dawg2-python>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from pymorphy3) (0.9.0)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.11/dist-packages (from pymorphy3) (2.4.417150.4580142)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "pip install pymorphy3 nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import pymorphy3\n",
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "id": "M6pH1gEPh0e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5da0cbc6-fa3b-48b5-c4d6-6c0cd1bc1d7d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_text = (\n",
        "    \"About two years ago, in 1808, after returning to St. Petersburg from his \"\n",
        "    \"trip to the estates, Pierre unwittingly became the head of St. Petersburg \"\n",
        "    \"Freemasonry. He set up mess halls and funeral lodges, recruited new \"\n",
        "    \"members, took care of connecting the various lodges and acquiring \"\n",
        "    \"authentic acts. He gave his money for the construction of temples and \"\n",
        "    \"replenished, as much as he could, the collection of alms, for which most \"\n",
        "    \"of the members were stingy and careless. He supported the poor house set \"\n",
        "    \"up by the order in St. Petersburg almost alone at his own expense.\"\n",
        ")\n",
        "\n",
        "russian_text = (\n",
        "    \"Года два тому назад, в 1808 году, вернувшись в Петербург из своей поездки \"\n",
        "    \"по имениям, Пьер невольно стал во главе петербургского масонства. Он \"\n",
        "    \"устроивал столовые и надгробные ложи, вербовал новых членов, заботился о \"\n",
        "    \"соединении различных лож и о приобретении подлинных актов. Он давал свои \"\n",
        "    \"деньги на устройство храмин и пополнял, насколько мог, сборы милостыни, \"\n",
        "    \"на которые большинство членов были скупы и неаккуратны. Он почти один на \"\n",
        "    \"свои средства поддерживал дом бедных, устроенный орденом в Петербурге.\"\n",
        ")"
      ],
      "metadata": {
        "id": "GQwMcAt5nJPG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Лемматизация**"
      ],
      "metadata": {
        "id": "AUNSiBTka4n0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos(tag):\n",
        "    tag_dict = {\n",
        "        'J': wordnet.ADJ,\n",
        "        'V': wordnet.VERB,\n",
        "        'N': wordnet.NOUN,\n",
        "        'R': wordnet.ADV\n",
        "    }\n",
        "    return tag_dict.get(tag[0], None)\n",
        "\n",
        "\n",
        "def lemmatize(text, lang):\n",
        "  if lang == 'english':\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [word.lower() for word in text.split()]\n",
        "    tagged_words = nltk.pos_tag(words)\n",
        "    lemmatized_words = []\n",
        "    for word, tag in tagged_words:\n",
        "      pos = get_wordnet_pos(tag)\n",
        "      if pos is not None:\n",
        "        lemma = lemmatizer.lemmatize(word, pos=pos)\n",
        "        lemmatized_words.append(lemma)\n",
        "      else:\n",
        "        lemmatized_words.append(word)\n",
        "    return \" \".join(lemmatized_words)\n",
        "\n",
        "  elif lang == 'russian':\n",
        "    morph = pymorphy3.MorphAnalyzer()\n",
        "    lemmatized_words = [morph.parse(word)[0].normal_form for word in text.split()]\n",
        "    return \" \".join(lemmatized_words)\n",
        "  else:\n",
        "    print(\"Error\")\n",
        "\n",
        "\n",
        "lemmatized_english_text = lemmatize(english_text, lang='english')\n",
        "lemmatized_russian_text = lemmatize(russian_text, lang='russian')\n",
        "\n",
        "print(\"Лемматизация:\", lemmatized_english_text)\n",
        "print(\"Лемматизация:\", lemmatized_russian_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsOHMmZ_lAit",
        "outputId": "ae0c7fe9-c18e-4eb2-ef88-dce046ec73bf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лемматизация: about two year ago, in 1808, after return to st. petersburg from his trip to the estates, pierre unwittingly become the head of st. petersburg freemasonry. he set up mess hall and funeral lodges, recruit new members, take care of connect the various lodge and acquire authentic acts. he give his money for the construction of temple and replenished, as much as he could, the collection of alms, for which most of the member be stingy and careless. he support the poor house set up by the order in st. petersburg almost alone at his own expense.\n",
            "Лемматизация: год два тот назад, в 1808 году, вернуться в петербург из свой поездка по имениям, пьер невольно стать в глава петербургский масонства. он устроивать столовая и надгробный ложи, вербовать новый членов, заботиться о соединение различный ложа и о приобретение подлинный актов. он давать свой деньга на устройство храмина и пополнял, насколько мог, сбор милостыни, на который большинство член быть скупой и неаккуратны. он почти один на свой средство поддерживать дом бедных, устроенный орден в петербурге.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Стемминг**"
      ],
      "metadata": {
        "id": "5T2TN187a8mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stemming(text, lang):\n",
        "  stemmer = SnowballStemmer(lang)\n",
        "  stemmed_text = [stemmer.stem(word) for word in text.split()]\n",
        "  joined_stemmed_text = \" \".join(stemmed_text)\n",
        "  return joined_stemmed_text\n",
        "\n",
        "\n",
        "stemming_english_text = stemming(english_text, 'english')\n",
        "stemming_russian_text = stemming(russian_text, 'russian')\n",
        "\n",
        "print(\"Стемминг:\", stemming_english_text)\n",
        "print(\"Стемминг:\", stemming_russian_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAdBAOKeuvEN",
        "outputId": "856e13c6-c585-4e8e-c318-1d7735720673"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Стемминг: about two year ago, in 1808, after return to st. petersburg from his trip to the estates, pierr unwit becam the head of st. petersburg freemasonry. he set up mess hall and funer lodges, recruit new members, took care of connect the various lodg and acquir authent acts. he gave his money for the construct of templ and replenished, as much as he could, the collect of alms, for which most of the member were stingi and careless. he support the poor hous set up by the order in st. petersburg almost alon at his own expense.\n",
            "Стемминг: год два том назад, в 1808 году, вернувш в петербург из сво поездк по имениям, пьер невольн стал во глав петербургск масонства. он устроива столов и надгробн ложи, вербова нов членов, забот о соединен различн лож и о приобретен подлин актов. он дава сво деньг на устройств храмин и пополнял, наскольк мог, сбор милостыни, на котор большинств член был скуп и неаккуратны. он почт один на сво средств поддержива дом бедных, устроен орден в петербурге.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Токенизация**"
      ],
      "metadata": {
        "id": "JDknYRCabAEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text: str) -> list[str]:\n",
        "  tokens = []\n",
        "  for char in text:\n",
        "    if char.isascii():\n",
        "      tokens.append(char.lower())\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "2REkoRCFw3Wl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_text_1 = \"Текст для проверки работы пользовательской функции токенизации.\"\n",
        "test_text_2 = (\n",
        "          \"Text for verifying the operation of a custom tokenization function.\"\n",
        ")\n",
        "\n",
        "test_tokenize_text_1 = tokenize(test_text_1)\n",
        "test_tokenize_text_2 = tokenize(test_text_2)\n",
        "\n",
        "print(\"Тест 1: \", test_tokenize_text_1)\n",
        "print(\"Тест 2: \", tokenize(test_text_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3OZb5ojzj5u",
        "outputId": "15f82290-f1ce-441e-cb90-ec8476773184"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Тест 1:  [' ', ' ', ' ', ' ', ' ', ' ', '.']\n",
            "Тест 2:  ['t', 'e', 'x', 't', ' ', 'f', 'o', 'r', ' ', 'v', 'e', 'r', 'i', 'f', 'y', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 'o', 'p', 'e', 'r', 'a', 't', 'i', 'o', 'n', ' ', 'o', 'f', ' ', 'a', ' ', 'c', 'u', 's', 't', 'o', 'm', ' ', 't', 'o', 'k', 'e', 'n', 'i', 'z', 'a', 't', 'i', 'o', 'n', ' ', 'f', 'u', 'n', 'c', 't', 'i', 'o', 'n', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Векторизация**"
      ],
      "metadata": {
        "id": "DN5fs08ybDqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(tokens: list[str]) -> list[int]:\n",
        "  vectors = [ord(char) for char in tokens]\n",
        "  return vectors"
      ],
      "metadata": {
        "id": "UUAhjtRQ5KCV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_vectorize_text_1 = vectorize(test_tokenize_text_1)\n",
        "test_vectorize_text_2 = vectorize(test_tokenize_text_2)\n",
        "\n",
        "print(\"Тест 3: \", test_vectorize_text_1)\n",
        "print(\"Тест 4: \", test_vectorize_text_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwaC-jYj87mu",
        "outputId": "2a17dd5f-e3e4-436a-84d9-47795945f2b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Тест 3:  [32, 32, 32, 32, 32, 32, 46]\n",
            "Тест 4:  [116, 101, 120, 116, 32, 102, 111, 114, 32, 118, 101, 114, 105, 102, 121, 105, 110, 103, 32, 116, 104, 101, 32, 111, 112, 101, 114, 97, 116, 105, 111, 110, 32, 111, 102, 32, 97, 32, 99, 117, 115, 116, 111, 109, 32, 116, 111, 107, 101, 110, 105, 122, 97, 116, 105, 111, 110, 32, 102, 117, 110, 99, 116, 105, 111, 110, 46]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Токенизация и векторизация после лемматизации**"
      ],
      "metadata": {
        "id": "P_byNnJValac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_lemmatized_text = tokenize(lemmatized_english_text)\n",
        "print(tokenize_lemmatized_text[:45])\n",
        "\n",
        "vectorize_lemmatized_text = vectorize(tokenize_lemmatized_text)\n",
        "print(vectorize_lemmatized_text[:45])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2g41xWVBuyd",
        "outputId": "5d2a9ddf-c106-4a3c-df6e-e631fadd8a70"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'b', 'o', 'u', 't', ' ', 't', 'w', 'o', ' ', 'y', 'e', 'a', 'r', ' ', 'a', 'g', 'o', ',', ' ', 'i', 'n', ' ', '1', '8', '0', '8', ',', ' ', 'a', 'f', 't', 'e', 'r', ' ', 'r', 'e', 't', 'u', 'r', 'n', ' ', 't', 'o', ' ']\n",
            "[97, 98, 111, 117, 116, 32, 116, 119, 111, 32, 121, 101, 97, 114, 32, 97, 103, 111, 44, 32, 105, 110, 32, 49, 56, 48, 56, 44, 32, 97, 102, 116, 101, 114, 32, 114, 101, 116, 117, 114, 110, 32, 116, 111, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Токенизация и векторизация после стемминга**"
      ],
      "metadata": {
        "id": "a74aaAMmaxAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_stemmed_text = tokenize(stemming_english_text)\n",
        "print(tokenize_stemmed_text[:45])\n",
        "\n",
        "vectorize_stemmed_text = vectorize(tokenize_stemmed_text)\n",
        "print(vectorize_stemmed_text[:45])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oho86fuca23E",
        "outputId": "cc963ad2-6a0b-4f16-95d8-249585966dbd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'b', 'o', 'u', 't', ' ', 't', 'w', 'o', ' ', 'y', 'e', 'a', 'r', ' ', 'a', 'g', 'o', ',', ' ', 'i', 'n', ' ', '1', '8', '0', '8', ',', ' ', 'a', 'f', 't', 'e', 'r', ' ', 'r', 'e', 't', 'u', 'r', 'n', ' ', 't', 'o', ' ']\n",
            "[97, 98, 111, 117, 116, 32, 116, 119, 111, 32, 121, 101, 97, 114, 32, 97, 103, 111, 44, 32, 105, 110, 32, 49, 56, 48, 56, 44, 32, 97, 102, 116, 101, 114, 32, 114, 101, 116, 117, 114, 110, 32, 116, 111, 32]\n"
          ]
        }
      ]
    }
  ]
}